# ğŸ“Š InsightGen â€“ AI-Powered Data Analysis Assistant (Runs 100% Locally)

InsightGen is your personal data analyst â€“ built with Gradio and powered by local LLMs using Ollama (like Mistral or LLaMA 2). It allows you to upload a CSV file and ask natural language questions about your data. The app returns Python code, plain-English explanations, and even chart instructions â€” all **without any internet or API keys**.

---

## ğŸš€ Features

âœ… Upload your own CSV file  
âœ… Ask questions in plain English like:  
&nbsp;&nbsp;&nbsp;&nbsp;â€¢ *"What is the average age of patients?"*  
&nbsp;&nbsp;&nbsp;&nbsp;â€¢ *"Show a bar chart of patients by Site_ID"*  
âœ… Get back:
- Python code using pandas
- Step-by-step explanation
- Expected output description

âœ… Powered by open-source LLMs (e.g. Mistral via Ollama)  
âœ… Built with Python + Gradio  
âœ… 100% runs locally (no OpenAI key required)

---

## ğŸ§  How It Works

1. **Upload CSV**: Load a dataset like `Patient.csv`.
2. **Gradio UI**: Shows a preview and suggests smart questions.
3. **Ask a Question**: Enter a natural language prompt.
4. **Ollama Response**: A local LLM converts your question into pandas code and explanations.
5. **Insight Display**: You get the generated code and insight in the UI.

---

## ğŸ’» Local Setup

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/InsightGen.git
cd InsightGen
```

2. Install Dependencies
```bash
pip install -r requirements.txt
```
Make sure ollama is installed: https://ollama.com

3. Start Ollama
```bash
ollama run mistral
```

4. Run the App
```bash
python app.py
```

Visit: http://localhost:7860

ğŸ› ï¸ Tech Stack
ğŸ§  Ollama â€“ Local LLM runtime
ğŸ¤– Mistral / LLaMA 2 â€“ LLM models
ğŸ¼ Pandas â€“ Data analysis
ğŸ–¼ï¸ Gradio â€“ User interface
ğŸ“Š Matplotlib / Seaborn (future: for chart rendering)

ğŸ“Œ Roadmap
 Add support for plotting charts
 Enable voice-to-question (Whisper)
 Add RAG support for multi-file analysis
 Export insights to PDF
 Session memory (chat history)
